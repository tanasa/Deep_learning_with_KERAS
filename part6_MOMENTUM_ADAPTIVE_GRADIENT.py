# -*- coding: utf-8 -*-
"""hw6_v2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1h0MfO4vtKy0P1bsGd2-R8aY8hdo3Q8hU
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
from sklearn.metrics import confusion_matrix, accuracy_score
import keras as keras
import math
from keras.models import Sequential
from keras.layers import Dense, Activation
from datascience import *
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
# %matplotlib inline

def z(x,y) : 
    z = -1 * math.sqrt(25 - (x-2)**2 - (y-3)**2)
    return(z)

def dz_dx(x,y) : 
    res = (x-2) / math.sqrt(25 - (x-2)**2 - (y-3)**2)
    return(res)

def dz_dy(x,y) : 
    res = (y-3) / math.sqrt(25 - (x-2)**2 - (y-3)**2)
    return(res)

xHistory = np.tile(np.float32(0), maxLimit)
yHistory = np.tile(np.float32(0), maxLimit)

learning_rate = 0.01
xStart = 0.3
yStart = 0.3
maxLimit = 5000

converged = False
i = -1
epsilon = 0.000001



# for i in range(1,maxLimit):
while (not converged): 
      xHistory[i] = xStart
      yHistory[i] = yStart

      deltaW = dz_dx(xStart, yStart)
      deltaB = dz_dy(xStart, yStart) 

      xStart = xStart - learning_rate * deltaW 
      yStart = yStart - learning_rate * deltaB

      xDifference = xStart - xHistory[i]
      yDifference = yStart - yHistory[i]

      if (( xDifference < epsilon ) & (yDifference < epsilon )):
           converged = True
           print("Number of steps taken to converge=",i+1,"\n")

print("Last Value of x = ", xHistory[i],"\n")
print("Last Value of x = ", yHistory[i],"\n")

fig = plt.figure()
ax = plt.axes()

ax.plot(xHistory)
ax.plot(yHistory)



xHistory = np.tile(np.float32(0), maxLimit)
yHistory = np.tile(np.float32(0), maxLimit)

learning_rate = 0.01
xStart = 0.3
yStart = 0.3
maxLimit = 5000

converged = False
i = -1
epsilon = 0.000001

xHistory = np.tile(np.float32(0), maxLimit)
yHistory = np.tile(np.float32(0), maxLimit)

gamma = 0.9
update = 0

Xupdate = np.tile(np.float32(0), maxLimit)
Yupdate = np.tile(np.float32(0), maxLimit)

# for i in range(1,maxLimit):
while (not converged): 
      i = i + 1
      xHistory[i] = xStart
      yHistory[i] = yStart

      Xgradient = dz_dx(xStart, yStart)
      Ygradient = dz_dy(xStart, yStart) 

      Xupdate[i] = (gamma * Xupdate[i]) + (learning_rate * Xgradient)
      Yupdate[i] = (gamma * Yupdate[i]) + (learning_rate * Ygradient)      

      xStart = xStart - Xupdate[i]
      yStart = yStart - Yupdate[i]

      xDifference = xStart - xHistory[i]
      yDifference = yStart - yHistory[i]

      if (( xDifference < epsilon ) & (yDifference < epsilon )):
           converged = True
           print("Number of steps taken to converge=",i+1,"\n")

print("Last Value of x = ", xHistory[i],"\n")
print("Last Value of x = ", yHistory[i],"\n")

fig = plt.figure()
ax = plt.axes()

ax.plot(xHistory)
ax.plot(yHistory)







